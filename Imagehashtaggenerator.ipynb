{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imagehashtaggenerator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M1GFF091JP1",
        "outputId": "731cdb27-4b96-41a1-90d5-ef29713b7521"
      },
      "source": [
        "!gdown --id 16OaU9XuXOonte_lAvYth51BaTQXAf7GK"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16OaU9XuXOonte_lAvYth51BaTQXAf7GK\n",
            "To: /content/Hashtaggenerator.zip\n",
            "53.3MB [00:00, 143MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeS-rPG1CG-e",
        "outputId": "1d30e6e9-6bef-4a0a-d5f7-73e4889b86d1"
      },
      "source": [
        "!unzip '/content/Hashtaggenerator.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Hashtaggenerator.zip\n",
            "   creating: Hashtag generator/.git/\n",
            "   creating: Hashtag generator/.git/branches/\n",
            "  inflating: Hashtag generator/.git/config  \n",
            "  inflating: Hashtag generator/.git/description  \n",
            " extracting: Hashtag generator/.git/HEAD  \n",
            "   creating: Hashtag generator/.git/hooks/\n",
            "  inflating: Hashtag generator/.git/hooks/applypatch-msg.sample  \n",
            "  inflating: Hashtag generator/.git/hooks/commit-msg.sample  \n",
            "  inflating: Hashtag generator/.git/hooks/fsmonitor-watchman.sample  \n",
            "  inflating: Hashtag generator/.git/hooks/post-update.sample  \n",
            "  inflating: Hashtag generator/.git/hooks/pre-applypatch.sample  \n",
            "  inflating: Hashtag generator/.git/hooks/pre-commit.sample  \n",
            "  inflating: Hashtag generator/.git/hooks/prepare-commit-msg.sample  \n",
            "  inflating: Hashtag generator/.git/hooks/pre-push.sample  \n",
            "  inflating: Hashtag generator/.git/hooks/pre-rebase.sample  \n",
            "  inflating: Hashtag generator/.git/hooks/pre-receive.sample  \n",
            "  inflating: Hashtag generator/.git/hooks/update.sample  \n",
            "  inflating: Hashtag generator/.git/index  \n",
            "   creating: Hashtag generator/.git/info/\n",
            "  inflating: Hashtag generator/.git/info/exclude  \n",
            "   creating: Hashtag generator/.git/logs/\n",
            "  inflating: Hashtag generator/.git/logs/HEAD  \n",
            "   creating: Hashtag generator/.git/logs/refs/\n",
            "   creating: Hashtag generator/.git/logs/refs/heads/\n",
            "  inflating: Hashtag generator/.git/logs/refs/heads/main  \n",
            "   creating: Hashtag generator/.git/logs/refs/remotes/\n",
            "   creating: Hashtag generator/.git/logs/refs/remotes/origin/\n",
            "  inflating: Hashtag generator/.git/logs/refs/remotes/origin/HEAD  \n",
            "   creating: Hashtag generator/.git/objects/\n",
            "   creating: Hashtag generator/.git/objects/14/\n",
            " extracting: Hashtag generator/.git/objects/14/894f80e57ce98120bb6c9d3211cdd6b5e045bf  \n",
            "   creating: Hashtag generator/.git/objects/17/\n",
            " extracting: Hashtag generator/.git/objects/17/5803d4f23727d3d0f7dda49e76b1fffadc63ba  \n",
            "   creating: Hashtag generator/.git/objects/19/\n",
            " extracting: Hashtag generator/.git/objects/19/ff89edf3dcb5834e21b89805c0943074e53db7  \n",
            "   creating: Hashtag generator/.git/objects/1b/\n",
            " extracting: Hashtag generator/.git/objects/1b/96f26c63b5be12e3a0155dd9e640ba817bd63f  \n",
            "   creating: Hashtag generator/.git/objects/31/\n",
            " extracting: Hashtag generator/.git/objects/31/de522454b65e963e5f8185c28b025635ab08b3  \n",
            "   creating: Hashtag generator/.git/objects/39/\n",
            " extracting: Hashtag generator/.git/objects/39/43dfe54e74743feb29ff0f0923e78dc281b9c6  \n",
            "   creating: Hashtag generator/.git/objects/44/\n",
            " extracting: Hashtag generator/.git/objects/44/3778d9b0dfa6c321372321e4c5a6165ba2269c  \n",
            "   creating: Hashtag generator/.git/objects/4b/\n",
            " extracting: Hashtag generator/.git/objects/4b/260b2496aa3695f1dc4431e7f447b2d2b82139  \n",
            "   creating: Hashtag generator/.git/objects/51/\n",
            " extracting: Hashtag generator/.git/objects/51/e528e36af3d270d51bc680b203786629df062d  \n",
            "   creating: Hashtag generator/.git/objects/53/\n",
            " extracting: Hashtag generator/.git/objects/53/6285fd6b9c038d8f7e3245828c27dcf52e59ed  \n",
            "   creating: Hashtag generator/.git/objects/5a/\n",
            " extracting: Hashtag generator/.git/objects/5a/fffce8d01ed20e3942d5af04e964188aa80eb3  \n",
            "   creating: Hashtag generator/.git/objects/61/\n",
            " extracting: Hashtag generator/.git/objects/61/9b184b90c8ca8cd87ecb7d693ab6ef0c770061  \n",
            "   creating: Hashtag generator/.git/objects/8c/\n",
            " extracting: Hashtag generator/.git/objects/8c/25f24386d264db05961808614ac7f441e483fa  \n",
            "   creating: Hashtag generator/.git/objects/a4/\n",
            " extracting: Hashtag generator/.git/objects/a4/679632afe09819c46f25e62a5c9e41a37d922c  \n",
            "   creating: Hashtag generator/.git/objects/af/\n",
            " extracting: Hashtag generator/.git/objects/af/6b616c3d2d7b1051bc09612b7637f5ae58e02a  \n",
            "   creating: Hashtag generator/.git/objects/bf/\n",
            " extracting: Hashtag generator/.git/objects/bf/e327f29d327a864519b4579bc026fb8898efea  \n",
            "   creating: Hashtag generator/.git/objects/c9/\n",
            " extracting: Hashtag generator/.git/objects/c9/b8c56eec01799b36391af07207facf45f60ba2  \n",
            "   creating: Hashtag generator/.git/objects/cb/\n",
            " extracting: Hashtag generator/.git/objects/cb/3e7e834d43e3c13b87822ae9e9726892139c29  \n",
            "   creating: Hashtag generator/.git/objects/d8/\n",
            " extracting: Hashtag generator/.git/objects/d8/eed9f10b6666c82470f64e3111a9e0a78eed00  \n",
            "   creating: Hashtag generator/.git/objects/eb/\n",
            " extracting: Hashtag generator/.git/objects/eb/970bb6c817ee0c56c6fbea95e0aca91d17bd91  \n",
            "   creating: Hashtag generator/.git/objects/f3/\n",
            " extracting: Hashtag generator/.git/objects/f3/450f11b5e9a6107ff733a2df967810c537914c  \n",
            "   creating: Hashtag generator/.git/objects/f4/\n",
            " extracting: Hashtag generator/.git/objects/f4/1fdf4d3eb6a37ed913fb000a0972f274376a64  \n",
            "   creating: Hashtag generator/.git/objects/fe/\n",
            " extracting: Hashtag generator/.git/objects/fe/6a07f49da98de1e2db953666126a4a8c701043  \n",
            " extracting: Hashtag generator/.git/objects/fe/8651683a300b38697ca1e0936e77c91e73b4f0  \n",
            "   creating: Hashtag generator/.git/objects/ff/\n",
            " extracting: Hashtag generator/.git/objects/ff/840c2740b429f3cd5a24d75c52d153f05d8edc  \n",
            " extracting: Hashtag generator/.git/objects/ff/9474ae9bb49f893e58d89cca3aa5d219331c8f  \n",
            "   creating: Hashtag generator/.git/objects/info/\n",
            "   creating: Hashtag generator/.git/objects/pack/\n",
            "  inflating: Hashtag generator/.git/packed-refs  \n",
            "   creating: Hashtag generator/.git/refs/\n",
            "   creating: Hashtag generator/.git/refs/heads/\n",
            " extracting: Hashtag generator/.git/refs/heads/main  \n",
            "   creating: Hashtag generator/.git/refs/remotes/\n",
            "   creating: Hashtag generator/.git/refs/remotes/origin/\n",
            " extracting: Hashtag generator/.git/refs/remotes/origin/HEAD  \n",
            "   creating: Hashtag generator/.git/refs/tags/\n",
            "  inflating: Hashtag generator/app.py  \n",
            "  inflating: Hashtag generator/create_model_vocabulary.ipynb  \n",
            "  inflating: Hashtag generator/LICENSE  \n",
            "  inflating: Hashtag generator/mine_model_weights.h5  \n",
            "  inflating: Hashtag generator/model.h5  \n",
            "  inflating: Hashtag generator/non_interactive.py  \n",
            "  inflating: Hashtag generator/README.md  \n",
            "   creating: Hashtag generator/static/\n",
            "  inflating: Hashtag generator/static/purple.jfif  \n",
            "  inflating: Hashtag generator/synonyms.py  \n",
            "   creating: Hashtag generator/templates/\n",
            "  inflating: Hashtag generator/templates/after.html  \n",
            "  inflating: Hashtag generator/templates/base.html  \n",
            "  inflating: Hashtag generator/templates/index.html  \n",
            "  inflating: Hashtag generator/templates/purple.jfif  \n",
            "  inflating: Hashtag generator/templates/styles.css  \n",
            "   creating: Hashtag generator/utilities/\n",
            " extracting: Hashtag generator/utilities/__init__.py  \n",
            "   creating: Hashtag generator/utilities/__pycache__/\n",
            "  inflating: Hashtag generator/utilities/__pycache__/__init__.cpython-38.pyc  \n",
            "  inflating: Hashtag generator/utilities/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: Hashtag generator/utilities/__pycache__/basic_soup.cpython-38.pyc  \n",
            "  inflating: Hashtag generator/utilities/__pycache__/basic_soup.cpython-39.pyc  \n",
            "  inflating: Hashtag generator/utilities/__pycache__/caching.cpython-38.pyc  \n",
            "  inflating: Hashtag generator/utilities/__pycache__/caching.cpython-39.pyc  \n",
            "  inflating: Hashtag generator/utilities/__pycache__/cleansing.cpython-38.pyc  \n",
            "  inflating: Hashtag generator/utilities/__pycache__/cleansing.cpython-39.pyc  \n",
            "  inflating: Hashtag generator/utilities/__pycache__/word_verification.cpython-38.pyc  \n",
            "  inflating: Hashtag generator/utilities/__pycache__/word_verification.cpython-39.pyc  \n",
            "  inflating: Hashtag generator/utilities/__pycache__/wordhoard_logger.cpython-38.pyc  \n",
            "  inflating: Hashtag generator/utilities/basic_soup.py  \n",
            "  inflating: Hashtag generator/utilities/caching.py  \n",
            "  inflating: Hashtag generator/utilities/cleansing.py  \n",
            "  inflating: Hashtag generator/utilities/word_verification.py  \n",
            "  inflating: Hashtag generator/utilities/wordhoard_logger.py  \n",
            "  inflating: Hashtag generator/vocab.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxMHAEo_CKwu",
        "outputId": "1bb830b7-d7a3-4b8d-ddf7-4e31d9faec8f"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uuY8WKwCKzj",
        "outputId": "46d426ce-82fe-46e1-d802-62987a83dc0a"
      },
      "source": [
        "from flask import Flask, render_template, request\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.optimizers import adam_v2\n",
        "from keras.layers import Dense, Flatten,Input, Convolution2D, Dropout, LSTM, TimeDistributed, Embedding, Bidirectional, Activation, RepeatVector,Concatenate\n",
        "from keras.models import Sequential, Model\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import image, sequence\n",
        "import cv2\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "from synonyms import Synonyms\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "vocab = np.load('/content/Hashtaggenerator/vocab.npy', allow_pickle=True)\n",
        "\n",
        "vocab = vocab.item()\n",
        "\n",
        "inv_vocab = {v:k for k,v in vocab.items()}\n",
        "\n",
        "\n",
        "print(\"+\"*50)\n",
        "print(\"vocabulary loaded\")\n",
        "\n",
        "\n",
        "embedding_size = 128\n",
        "vocab_size = len(vocab)\n",
        "max_len = 40\n",
        "\n",
        "\n",
        "image_model = Sequential()\n",
        "\n",
        "image_model.add(Dense(embedding_size, input_shape=(2048,), activation='relu'))\n",
        "image_model.add(RepeatVector(max_len))\n",
        "\n",
        "\n",
        "language_model = Sequential()\n",
        "\n",
        "language_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_len))\n",
        "language_model.add(LSTM(256, return_sequences=True))\n",
        "language_model.add(TimeDistributed(Dense(embedding_size)))\n",
        "\n",
        "conca = Concatenate()([image_model.output, language_model.output])\n",
        "x = LSTM(128, return_sequences=True)(conca)\n",
        "x = LSTM(512, return_sequences=False)(x)\n",
        "x = Dense(vocab_size)(x)\n",
        "out = Activation('softmax')(x)\n",
        "model = Model(inputs=[image_model.input, language_model.input], outputs = out)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "\n",
        "model.load_weights('/content/Hashtaggenerator/mine_model_weights.h5')\n",
        "\n",
        "print(\"=\"*150)\n",
        "print(\"MODEL LOADED\")\n",
        "\n",
        "resnet = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),pooling='avg')\n",
        "\n",
        "\n",
        "#resnet = load_model('/content/image-captioning-keras-resnet/model.h5')\n",
        "\n",
        "print(\"=\"*150)\n",
        "print(\"RESNET MODEL LOADED\")\n",
        "\n",
        "\n",
        "app = Flask(__name__,template_folder=\"/content/Hashtaggenerator/templates\",static_url_path='/content/Hashtaggenerator/static')\n",
        "run_with_ngrok(app)\n",
        "\n",
        "app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 1\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/after', methods=['GET', 'POST'])\n",
        "def after():\n",
        "\n",
        "    global model, resnet, vocab, inv_vocab\n",
        "\n",
        "    img = request.files['file1']\n",
        "\n",
        "    img.save('/content/Hashtaggenerator/static/file.jpg')\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"IMAGE SAVED\")\n",
        "\n",
        "\n",
        "    \n",
        "    image = cv2.imread('/content/Hashtaggenerator/static/file.jpg')\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    image = cv2.resize(image, (224,224))\n",
        "\n",
        "    image = np.reshape(image, (1,224,224,3))\n",
        "\n",
        "    \n",
        "    \n",
        "    incept = resnet.predict(image).reshape(1,2048)\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"Predict Features\")\n",
        "\n",
        "\n",
        "    text_in = ['startofseq']\n",
        "\n",
        "    final = ''\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"GETING Captions\")\n",
        "\n",
        "    count = 0\n",
        "    while tqdm(count < 20):\n",
        "\n",
        "        count += 1\n",
        "\n",
        "        encoded = []\n",
        "        for i in text_in:\n",
        "            encoded.append(vocab[i])\n",
        "\n",
        "        padded = pad_sequences([encoded], maxlen=max_len, padding='post', truncating='post').reshape(1,max_len)\n",
        "\n",
        "        sampled_index = np.argmax(model.predict([incept, padded]))\n",
        "\n",
        "        sampled_word = inv_vocab[sampled_index]\n",
        "\n",
        "        if sampled_word != 'endofseq':\n",
        "            final = final + ' ' + sampled_word\n",
        "\n",
        "        text_in.append(sampled_word)\n",
        "    new_list=[]\n",
        "    new_string=''\n",
        "    meaning=[]\n",
        "    newl=''\n",
        "    nopunc = re.sub(r'[^\\w\\s]','', final)\n",
        "    final=[word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
        "    print(final)\n",
        "    for word in final:\n",
        "        new_list.append('#' + ''.join(word.split()))\n",
        "        var= Synonyms(word)\n",
        "        meaning=var.find_synonyms()\n",
        "        print(meaning)\n",
        "        for i in meaning:\n",
        "          new_list.append('#'+i)\n",
        "    random.shuffle(new_list)\n",
        "    new_list=new_list[:40]\n",
        "    new_string=''.join(new_list)\n",
        "    print(new_string)\n",
        "    return render_template('after.html', data=new_string) \n",
        "   \n",
        "if __name__ == \"__main__\":\n",
        "    app.run()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "vocabulary loaded\n",
            "======================================================================================================================================================\n",
            "MODEL LOADED\n",
            "======================================================================================================================================================\n",
            "RESNET MODEL LOADED\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://c99d-35-230-108-27.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        }
      ]
    }
  ]
}